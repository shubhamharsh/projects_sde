{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.0\n"
     ]
    }
   ],
   "source": [
    "import skimage as ski\n",
    "print(ski.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 19 persons, 104.8ms\n",
      "Speed: 1.7ms preprocess, 104.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 121.6ms\n",
      "Speed: 3.0ms preprocess, 121.6ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 112.3ms\n",
      "Speed: 2.0ms preprocess, 112.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 88.1ms\n",
      "Speed: 2.7ms preprocess, 88.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 101.9ms\n",
      "Speed: 2.3ms preprocess, 101.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 100.3ms\n",
      "Speed: 0.0ms preprocess, 100.3ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 93.2ms\n",
      "Speed: 2.0ms preprocess, 93.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 101.6ms\n",
      "Speed: 0.0ms preprocess, 101.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 93.5ms\n",
      "Speed: 0.0ms preprocess, 93.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 81.6ms\n",
      "Speed: 3.0ms preprocess, 81.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 90.3ms\n",
      "Speed: 1.5ms preprocess, 90.3ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 80.1ms\n",
      "Speed: 0.0ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 99.4ms\n",
      "Speed: 2.0ms preprocess, 99.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 100.6ms\n",
      "Speed: 0.0ms preprocess, 100.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 89.8ms\n",
      "Speed: 0.0ms preprocess, 89.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 87.1ms\n",
      "Speed: 1.0ms preprocess, 87.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 86.8ms\n",
      "Speed: 2.9ms preprocess, 86.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 99.1ms\n",
      "Speed: 2.6ms preprocess, 99.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 91.5ms\n",
      "Speed: 2.0ms preprocess, 91.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 87.6ms\n",
      "Speed: 1.0ms preprocess, 87.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 91.1ms\n",
      "Speed: 0.0ms preprocess, 91.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 81.9ms\n",
      "Speed: 0.0ms preprocess, 81.9ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 102.8ms\n",
      "Speed: 2.0ms preprocess, 102.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 90.5ms\n",
      "Speed: 0.0ms preprocess, 90.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 81.0ms\n",
      "Speed: 0.0ms preprocess, 81.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 95.6ms\n",
      "Speed: 4.0ms preprocess, 95.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 83.5ms\n",
      "Speed: 2.4ms preprocess, 83.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 persons, 83.3ms\n",
      "Speed: 4.0ms preprocess, 83.3ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 97.1ms\n",
      "Speed: 1.9ms preprocess, 97.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 86.1ms\n",
      "Speed: 0.0ms preprocess, 86.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 90.8ms\n",
      "Speed: 1.0ms preprocess, 90.8ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 88.3ms\n",
      "Speed: 1.0ms preprocess, 88.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 100.0ms\n",
      "Speed: 2.8ms preprocess, 100.0ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 111.0ms\n",
      "Speed: 1.0ms preprocess, 111.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 persons, 100.5ms\n",
      "Speed: 0.0ms preprocess, 100.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 persons, 99.6ms\n",
      "Speed: 0.0ms preprocess, 99.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 persons, 97.2ms\n",
      "Speed: 1.9ms preprocess, 97.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# cap = cv2.VideoCapture(0)  # For Webcam\n",
    "cap = cv2.VideoCapture('./people.mp4')\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 720)\n",
    "model = YOLO('./yolo-wts/yolov8n.pt')\n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            w, h = x2-x1, y2-y1\n",
    "            bbox = int(x1),int(y1),int(w),int(h)\n",
    "            # cv2.rectangle(img, (x1,y1), (x2,y2),(255,0,255),3)\n",
    "            cvzone.cornerRect(img,(x1,y1,w,h))\n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "            cls = int(box.cls[0])\n",
    "            cvzone.putTextRect(img,f'{conf} {classNames[cls]}',(max(0,x1),max(40,y1)))\n",
    "            \n",
    "            # print(x1,y1,x2,y2)\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(1)\n",
    "    if cv2.getWindowProperty('image',cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
